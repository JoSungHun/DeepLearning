{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoSungHun/Deeplearning/blob/master/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6vFXgflvZ6Ga",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment"
      ]
    },
    {
      "metadata": {
        "id": "UevAU0CYVhiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Due date: **2018/04/09 00:00** (will not accept late submission)\n",
        "* Submittion format: notebook file which can be executed in Colab environment\n",
        "\n",
        "* We want to build a multi-class classification model using Reuters dataset."
      ]
    },
    {
      "metadata": {
        "id": "KxrhNNhWbfHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> ### Loading and preprocessing data"
      ]
    },
    {
      "metadata": {
        "id": "8E-2WLHgcAit",
        "colab_type": "code",
        "outputId": "9ff22373-c0b7-4b10-ebf2-13a1e55a33da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "# Like IMDB, the argument num_words restricts the data to \n",
        "# the 10,000 most frequently occurring words \n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yrjD9AerdW4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NmLRa5GNeSOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzoKfo9PUArN",
        "colab_type": "code",
        "outputId": "70cd6100-d30c-43c9-c5fa-824448a4999e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "yWfgUJiPeicE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> ### Building the network"
      ]
    },
    {
      "metadata": {
        "id": "Edwc4GbneqKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(46, activation='softmax'))\n",
        "  model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hxGWsKkdgAnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0TUwiHLgI_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> ### Validation"
      ]
    },
    {
      "metadata": {
        "id": "KFe4FOkfgUII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* We employ *k-fold cross validation* for monitoring the performance of trained model.\n",
        "* Write a code in the below to perform *10-fold cross validation*.\n",
        "* **For each fold, save a model at every epoch in your Google Drive.**"
      ]
    },
    {
      "metadata": {
        "id": "ZKOrz-PXN1nf",
        "colab_type": "code",
        "outputId": "daa2a677-deba-46f2-ab5c-eccaca088253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive#구글드라이브 마운트 및 파일경로 설정\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "drive.mount('/content/gdrive')\n",
        "filepath = '/content/gdrive/My Drive/hw2_14113359/hw2_model.{epoch:02d}.hdf5'\n",
        "modelckpt = Modelcheckpoint(filepath=filepath) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jPWjg2s4WYfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# write a code for 10-fold cross validation here\n",
        "import numpy as np\n",
        "k = 10\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 50\n",
        "all_train_acc = []\n",
        "all_val_acc = []\n",
        "for i in range(k):\n",
        "  print('처리중인 폴드 #', i)\n",
        "  \n",
        "  val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
        "  \n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
        "  partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
        "    \n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data,\n",
        "                      partial_train_targets,\n",
        "                      epochs=numepochs,\n",
        "                      batch_size=512,\n",
        "                      validation_data=(val_data, val_targets))\n",
        "  \n",
        "  train_acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  \n",
        "  all_train_acc.append(train_acc)\n",
        "  all_val_acc.append(val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8908muCWdnG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Plotting the training and validation accuracy\n",
        "  * To obtain the validation accuracy at the end of every epoch, just average the performances of all folds."
      ]
    },
    {
      "metadata": {
        "id": "6PJb3RyXXZlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# write a code for plotting the training and validation accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pS0D5_0iXd_y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> ### Inference"
      ]
    },
    {
      "metadata": {
        "id": "r9HNF524XkCy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Find the best performance model by seeing the performance plot.\n",
        "* Calculate the accuracy on test set using the best performance model.\n",
        "  * Here, you should use a majority voting method to get the prediction for a test data point.\n",
        "  * Specifically, given a test data point, get the predicted class from the trained model on each fold, and then decide the final predicted class by majority voting.\n",
        "* **Do not retrain the model.**"
      ]
    },
    {
      "metadata": {
        "id": "bhDWsnWuY5w-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# write a code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcEnfITPZNBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b4b78e7a-fcfa-4012-db18-b1d62061c09f"
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/JoSungHun/Deeplearning.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deeplearning'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)   \u001b[K\rremote: Counting objects:  10% (2/20)   \u001b[K\rremote: Counting objects:  15% (3/20)   \u001b[K\rremote: Counting objects:  20% (4/20)   \u001b[K\rremote: Counting objects:  25% (5/20)   \u001b[K\rremote: Counting objects:  30% (6/20)   \u001b[K\rremote: Counting objects:  35% (7/20)   \u001b[K\rremote: Counting objects:  40% (8/20)   \u001b[K\rremote: Counting objects:  45% (9/20)   \u001b[K\rremote: Counting objects:  50% (10/20)   \u001b[K\rremote: Counting objects:  55% (11/20)   \u001b[K\rremote: Counting objects:  60% (12/20)   \u001b[K\rremote: Counting objects:  65% (13/20)   \u001b[K\rremote: Counting objects:  70% (14/20)   \u001b[K\rremote: Counting objects:  75% (15/20)   \u001b[K\rremote: Counting objects:  80% (16/20)   \u001b[K\rremote: Counting objects:  85% (17/20)   \u001b[K\rremote: Counting objects:  90% (18/20)   \u001b[K\rremote: Counting objects:  95% (19/20)   \u001b[K\rremote: Counting objects: 100% (20/20)   \u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/18)   \u001b[K\rremote: Compressing objects:  11% (2/18)   \u001b[K\rremote: Compressing objects:  16% (3/18)   \u001b[K\rremote: Compressing objects:  22% (4/18)   \u001b[K\rremote: Compressing objects:  27% (5/18)   \u001b[K\rremote: Compressing objects:  33% (6/18)   \u001b[K\rremote: Compressing objects:  38% (7/18)   \u001b[K\rremote: Compressing objects:  44% (8/18)   \u001b[K\rremote: Compressing objects:  50% (9/18)   \u001b[K\rremote: Compressing objects:  55% (10/18)   \u001b[K\rremote: Compressing objects:  61% (11/18)   \u001b[K\rremote: Compressing objects:  66% (12/18)   \u001b[K\rremote: Compressing objects:  72% (13/18)   \u001b[K\rremote: Compressing objects:  77% (14/18)   \u001b[K\rremote: Compressing objects:  83% (15/18)   \u001b[K\rremote: Compressing objects:  88% (16/18)   \u001b[K\rremote: Compressing objects:  94% (17/18)   \u001b[K\rremote: Compressing objects: 100% (18/18)   \u001b[K\rremote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "Unpacking objects:   5% (1/20)   \rUnpacking objects:  10% (2/20)   \rUnpacking objects:  15% (3/20)   \rUnpacking objects:  20% (4/20)   \rUnpacking objects:  25% (5/20)   \rUnpacking objects:  30% (6/20)   \rUnpacking objects:  35% (7/20)   \rUnpacking objects:  40% (8/20)   \rremote: Total 20 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  45% (9/20)   \rUnpacking objects:  50% (10/20)   \rUnpacking objects:  55% (11/20)   \rUnpacking objects:  60% (12/20)   \rUnpacking objects:  65% (13/20)   \rUnpacking objects:  70% (14/20)   \rUnpacking objects:  75% (15/20)   \rUnpacking objects:  80% (16/20)   \rUnpacking objects:  85% (17/20)   \rUnpacking objects:  90% (18/20)   \rUnpacking objects:  95% (19/20)   \rUnpacking objects: 100% (20/20)   \rUnpacking objects: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}