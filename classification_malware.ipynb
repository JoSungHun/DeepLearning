{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_malware",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoSungHun/Deeplearning/blob/master/classification_malware.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv2yz7Qa0LCr",
        "colab_type": "code",
        "outputId": "c3c3939f-1490-43dc-e34d-f7ff5de9fc73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "drive.mount('/content/gdrive')\n",
        "vgg_callbackpath = '/content/gdrive/My Drive/DeepLearning_Project/2/vgg_callback/project_model.{epoch:02d}.hdf5'\n",
        "resnet_callbackpath = '/content/gdrive/My Drive/DeepLearning_Project/2/resnet_callback/project_model.{epoch:02d}.hdf5'\n",
        "resnet_callbackpath2 = '/content/gdrive/My Drive/DeepLearning_Project/2/resnet_callback/project_model2.{epoch:02d}.hdf5'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEPBtrbSSt0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "import os, shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.applications.resnet50 import ResNet50, decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyvhcqMFZ1s",
        "colab_type": "text"
      },
      "source": [
        "> ### Prepare the dataset and data processing\n",
        "\n",
        "* 데이터를 불러오고, train, validation, test로 데이터를 나눈다.\n",
        "* imageDataGenerator를 사용하여 generator를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqoRlHWwBdQd",
        "colab_type": "code",
        "outputId": "66f57eba-a9d8-4a00-bca3-a4da222de7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "dst_path = '/content/gdrive/My Drive/DeepLearning_Project/2/malware_image_dataset'\n",
        "\n",
        "train_worm_dir = os.path.join(dst_path, 'train/worm')\n",
        "train_others_dir = os.path.join(dst_path, 'train/others')\n",
        "\n",
        "validation_worm_dir = os.path.join(dst_path, 'validation/worm')\n",
        "validation_others_dir = os.path.join(dst_path, 'validation/others')\n",
        "\n",
        "test_worm_dir = os.path.join(dst_path, 'test/worm')\n",
        "test_others_dir = os.path.join(dst_path, 'test/others')\n",
        "\n",
        "train_dir = os.path.join(dst_path, 'train')\n",
        "val_dir = os.path.join(dst_path, 'validation')\n",
        "test_dir = os.path.join(dst_path, 'test')\n",
        "\n",
        "print('total training worm images:', len(os.listdir(train_worm_dir)))\n",
        "print('total training others images:', len(os.listdir(train_others_dir)))\n",
        "\n",
        "print('total validation worm images:', len(os.listdir(validation_worm_dir)))\n",
        "print('total validation others images:', len(os.listdir(validation_others_dir)))\n",
        "\n",
        "print('total test worm images:', len(os.listdir(test_worm_dir)))\n",
        "print('total test others images:', len(os.listdir(test_others_dir)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training worm images: 4054\n",
            "total training others images: 3286\n",
            "total validation worm images: 500\n",
            "total validation others images: 500\n",
            "total test worm images: 500\n",
            "total test others images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8_go-Z0Soyr",
        "colab_type": "code",
        "outputId": "1dd8a757-7750-4cbb-86bb-a7d9800e8aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "datagen = image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_batches = datagen.flow_from_directory(train_dir,\n",
        "                                      target_size=(64,64),\n",
        "                                      class_mode='binary',\n",
        "                                      shuffle=True,\n",
        "                                      batch_size=20)\n",
        "\n",
        "val_batches = datagen.flow_from_directory(val_dir,\n",
        "                                      target_size=(64,64),\n",
        "                                      class_mode='binary',\n",
        "                                      shuffle=True,\n",
        "                                      batch_size=20)\n",
        "\n",
        "test_batches = datagen.flow_from_directory(test_dir,\n",
        "                                      target_size=(64,64),\n",
        "                                      class_mode='binary',\n",
        "                                      shuffle=True,\n",
        "                                      batch_size=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7340 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvyhWeRNizNj",
        "colab_type": "text"
      },
      "source": [
        "> ### Build the network (Using VGG16)\n",
        "* vgg16 모델을 불러오고 그 위에 분류를 위한 레이어를 쌓는다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52jpV-BpgU2t",
        "colab_type": "code",
        "outputId": "13288ee9-60ed-4552-922b-913839d5cdf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "conv_base = VGG16(weights='imagenet', # imagenet으로 학습되어 있는 거를 가져옴.\n",
        "                  include_top=False,  # colvoultional base만 가져옴 위에것 떼어오고\n",
        "                  input_shape=(64, 64, 3)) # 우리것에 맞게 인풋을 조정"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bfP6-8oIQY",
        "colab_type": "code",
        "outputId": "564a6aba-0b00-48a2-a5f0-fb8be6221c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1qM9Vm6wOCe",
        "colab_type": "code",
        "outputId": "febef313-cb6e-4de9-b6a0-418a35515e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "conv_base.trainable = False\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 15,239,489\n",
            "Trainable params: 524,801\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQNQvYCpjl1a",
        "colab_type": "text"
      },
      "source": [
        "> ### Model Trainning\n",
        "* vgg16 모델을 불러오고 그 위에 분류를 위한 레이어를 쌓는다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ifeZzP499B",
        "colab_type": "code",
        "outputId": "cbbbb0f4-8785-47e4-81fc-7467acd02718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "modelckpt = ModelCheckpoint(filepath=vgg_callbackpath)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=367,\n",
        "                              epochs=10,\n",
        "                              validation_data=val_batches,\n",
        "                              validation_steps=50,\n",
        "                              callbacks=[modelckpt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "367/367 [==============================] - 593s 2s/step - loss: 0.1737 - acc: 0.9516 - val_loss: 0.1500 - val_acc: 0.9540\n",
            "Epoch 2/10\n",
            "367/367 [==============================] - 30s 81ms/step - loss: 0.1511 - acc: 0.9576 - val_loss: 0.1493 - val_acc: 0.9620\n",
            "Epoch 3/10\n",
            "367/367 [==============================] - 30s 81ms/step - loss: 0.1306 - acc: 0.9654 - val_loss: 0.1346 - val_acc: 0.9660\n",
            "Epoch 4/10\n",
            "367/367 [==============================] - 29s 80ms/step - loss: 0.1204 - acc: 0.9678 - val_loss: 0.1028 - val_acc: 0.9790\n",
            "Epoch 5/10\n",
            "367/367 [==============================] - 30s 81ms/step - loss: 0.1094 - acc: 0.9708 - val_loss: 0.1198 - val_acc: 0.9690\n",
            "Epoch 6/10\n",
            "367/367 [==============================] - 29s 79ms/step - loss: 0.1189 - acc: 0.9680 - val_loss: 0.1198 - val_acc: 0.9660\n",
            "Epoch 7/10\n",
            "367/367 [==============================] - 28s 78ms/step - loss: 0.1110 - acc: 0.9689 - val_loss: 0.1061 - val_acc: 0.9720\n",
            "Epoch 8/10\n",
            "367/367 [==============================] - 29s 80ms/step - loss: 0.1094 - acc: 0.9698 - val_loss: 0.1060 - val_acc: 0.9700\n",
            "Epoch 9/10\n",
            "367/367 [==============================] - 29s 80ms/step - loss: 0.0945 - acc: 0.9730 - val_loss: 0.1115 - val_acc: 0.9700\n",
            "Epoch 10/10\n",
            "367/367 [==============================] - 29s 79ms/step - loss: 0.0999 - acc: 0.9711 - val_loss: 0.1127 - val_acc: 0.9710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qM9EjUj-qjh",
        "colab_type": "code",
        "outputId": "62351d1e-fd8a-46ec-fd71-19710c975a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vgg_best_model = models.load_model(filepath='/content/gdrive/My Drive/DeepLearning_Project/2/vgg_callback/project_model.06.hdf5', compile=False)\n",
        "vgg_model_predict = vgg_best_model.predict_generator(test_batches, steps=50,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 89ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdMzFR_mSmHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)}) #  출력을 이쁘게"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e7FQBMNZlfR",
        "colab_type": "code",
        "outputId": "98ae22f5-d4d2-4d75-d04a-c16064c16a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18017
        }
      },
      "source": [
        " print(vgg_model_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.001]\n",
            " [0.971]\n",
            " [0.996]\n",
            " [0.996]\n",
            " [0.968]\n",
            " [0.977]\n",
            " [0.930]\n",
            " [0.091]\n",
            " [0.985]\n",
            " [0.984]\n",
            " [0.986]\n",
            " [0.980]\n",
            " [0.000]\n",
            " [0.003]\n",
            " [0.091]\n",
            " [0.092]\n",
            " [0.135]\n",
            " [0.033]\n",
            " [0.975]\n",
            " [0.998]\n",
            " [0.001]\n",
            " [0.979]\n",
            " [0.059]\n",
            " [0.029]\n",
            " [0.003]\n",
            " [0.981]\n",
            " [0.998]\n",
            " [0.000]\n",
            " [0.997]\n",
            " [0.304]\n",
            " [0.091]\n",
            " [0.988]\n",
            " [0.990]\n",
            " [0.091]\n",
            " [0.003]\n",
            " [0.995]\n",
            " [0.002]\n",
            " [0.947]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.857]\n",
            " [0.091]\n",
            " [0.012]\n",
            " [0.379]\n",
            " [0.010]\n",
            " [0.995]\n",
            " [0.993]\n",
            " [0.000]\n",
            " [0.921]\n",
            " [0.998]\n",
            " [0.037]\n",
            " [0.000]\n",
            " [0.229]\n",
            " [0.621]\n",
            " [0.091]\n",
            " [0.960]\n",
            " [0.979]\n",
            " [0.997]\n",
            " [0.940]\n",
            " [0.996]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.929]\n",
            " [0.968]\n",
            " [0.021]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.980]\n",
            " [0.975]\n",
            " [0.001]\n",
            " [0.001]\n",
            " [0.005]\n",
            " [0.996]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.824]\n",
            " [0.397]\n",
            " [0.983]\n",
            " [0.002]\n",
            " [0.001]\n",
            " [0.007]\n",
            " [0.103]\n",
            " [0.001]\n",
            " [0.999]\n",
            " [0.012]\n",
            " [0.091]\n",
            " [0.967]\n",
            " [0.091]\n",
            " [0.964]\n",
            " [0.998]\n",
            " [0.001]\n",
            " [0.003]\n",
            " [0.967]\n",
            " [0.016]\n",
            " [0.998]\n",
            " [0.091]\n",
            " [0.993]\n",
            " [0.962]\n",
            " [0.942]\n",
            " [0.998]\n",
            " [0.002]\n",
            " [0.158]\n",
            " [0.002]\n",
            " [0.008]\n",
            " [0.039]\n",
            " [0.103]\n",
            " [0.997]\n",
            " [0.924]\n",
            " [0.982]\n",
            " [0.999]\n",
            " [0.091]\n",
            " [0.998]\n",
            " [0.052]\n",
            " [0.995]\n",
            " [0.000]\n",
            " [0.996]\n",
            " [0.991]\n",
            " [0.132]\n",
            " [0.016]\n",
            " [0.026]\n",
            " [0.995]\n",
            " [0.965]\n",
            " [0.992]\n",
            " [0.971]\n",
            " [0.978]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.997]\n",
            " [0.014]\n",
            " [1.000]\n",
            " [1.000]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.492]\n",
            " [0.868]\n",
            " [0.998]\n",
            " [0.952]\n",
            " [0.001]\n",
            " [0.999]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.003]\n",
            " [0.067]\n",
            " [0.012]\n",
            " [0.995]\n",
            " [0.981]\n",
            " [0.091]\n",
            " [0.991]\n",
            " [0.501]\n",
            " [0.967]\n",
            " [0.986]\n",
            " [0.007]\n",
            " [0.001]\n",
            " [0.987]\n",
            " [0.990]\n",
            " [0.000]\n",
            " [0.890]\n",
            " [0.000]\n",
            " [0.832]\n",
            " [0.006]\n",
            " [0.991]\n",
            " [0.091]\n",
            " [0.999]\n",
            " [0.001]\n",
            " [0.995]\n",
            " [0.001]\n",
            " [0.002]\n",
            " [0.991]\n",
            " [0.001]\n",
            " [0.007]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.974]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.998]\n",
            " [0.991]\n",
            " [0.001]\n",
            " [0.967]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.002]\n",
            " [0.981]\n",
            " [0.954]\n",
            " [0.091]\n",
            " [0.997]\n",
            " [0.021]\n",
            " [0.990]\n",
            " [0.808]\n",
            " [0.001]\n",
            " [0.002]\n",
            " [0.962]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.997]\n",
            " [0.000]\n",
            " [0.925]\n",
            " [0.998]\n",
            " [0.965]\n",
            " [0.991]\n",
            " [0.996]\n",
            " [0.971]\n",
            " [0.003]\n",
            " [0.971]\n",
            " [0.091]\n",
            " [1.000]\n",
            " [0.983]\n",
            " [0.006]\n",
            " [0.981]\n",
            " [0.000]\n",
            " [0.987]\n",
            " [0.000]\n",
            " [0.003]\n",
            " [0.006]\n",
            " [0.979]\n",
            " [0.967]\n",
            " [0.987]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.975]\n",
            " [1.000]\n",
            " [0.091]\n",
            " [0.992]\n",
            " [0.962]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.969]\n",
            " [0.970]\n",
            " [0.984]\n",
            " [0.001]\n",
            " [0.910]\n",
            " [0.983]\n",
            " [0.091]\n",
            " [0.899]\n",
            " [0.002]\n",
            " [0.013]\n",
            " [0.877]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.120]\n",
            " [0.915]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.993]\n",
            " [0.091]\n",
            " [0.103]\n",
            " [0.982]\n",
            " [0.949]\n",
            " [0.000]\n",
            " [0.006]\n",
            " [0.990]\n",
            " [0.971]\n",
            " [0.049]\n",
            " [0.091]\n",
            " [0.027]\n",
            " [0.001]\n",
            " [0.968]\n",
            " [0.007]\n",
            " [0.924]\n",
            " [0.990]\n",
            " [0.976]\n",
            " [0.002]\n",
            " [0.033]\n",
            " [0.974]\n",
            " [0.013]\n",
            " [0.091]\n",
            " [0.996]\n",
            " [0.957]\n",
            " [0.965]\n",
            " [0.965]\n",
            " [0.006]\n",
            " [0.815]\n",
            " [0.027]\n",
            " [0.103]\n",
            " [0.775]\n",
            " [1.000]\n",
            " [0.000]\n",
            " [0.010]\n",
            " [0.004]\n",
            " [0.984]\n",
            " [0.000]\n",
            " [0.999]\n",
            " [0.039]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.371]\n",
            " [0.982]\n",
            " [0.997]\n",
            " [0.990]\n",
            " [0.998]\n",
            " [0.999]\n",
            " [0.987]\n",
            " [0.091]\n",
            " [0.688]\n",
            " [0.901]\n",
            " [0.987]\n",
            " [0.002]\n",
            " [0.103]\n",
            " [0.013]\n",
            " [0.001]\n",
            " [0.930]\n",
            " [0.995]\n",
            " [0.995]\n",
            " [0.001]\n",
            " [0.975]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.974]\n",
            " [0.091]\n",
            " [0.003]\n",
            " [0.000]\n",
            " [0.992]\n",
            " [0.981]\n",
            " [0.997]\n",
            " [0.991]\n",
            " [0.987]\n",
            " [0.081]\n",
            " [1.000]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.007]\n",
            " [0.010]\n",
            " [0.982]\n",
            " [0.049]\n",
            " [0.010]\n",
            " [0.824]\n",
            " [0.985]\n",
            " [0.986]\n",
            " [0.975]\n",
            " [0.052]\n",
            " [0.007]\n",
            " [0.000]\n",
            " [0.996]\n",
            " [0.996]\n",
            " [0.003]\n",
            " [0.996]\n",
            " [0.945]\n",
            " [0.998]\n",
            " [0.999]\n",
            " [0.967]\n",
            " [0.990]\n",
            " [0.997]\n",
            " [0.984]\n",
            " [0.970]\n",
            " [0.720]\n",
            " [0.990]\n",
            " [0.990]\n",
            " [0.997]\n",
            " [0.091]\n",
            " [0.997]\n",
            " [0.921]\n",
            " [0.007]\n",
            " [0.039]\n",
            " [0.998]\n",
            " [0.956]\n",
            " [0.001]\n",
            " [0.954]\n",
            " [0.091]\n",
            " [0.013]\n",
            " [0.996]\n",
            " [0.987]\n",
            " [0.004]\n",
            " [0.980]\n",
            " [0.914]\n",
            " [0.018]\n",
            " [0.059]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.999]\n",
            " [0.986]\n",
            " [1.000]\n",
            " [0.996]\n",
            " [0.000]\n",
            " [0.006]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.995]\n",
            " [0.091]\n",
            " [0.808]\n",
            " [0.994]\n",
            " [0.000]\n",
            " [0.103]\n",
            " [0.992]\n",
            " [0.537]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.980]\n",
            " [0.987]\n",
            " [0.122]\n",
            " [0.768]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.007]\n",
            " [0.007]\n",
            " [0.965]\n",
            " [0.001]\n",
            " [0.001]\n",
            " [0.976]\n",
            " [0.000]\n",
            " [0.007]\n",
            " [0.994]\n",
            " [0.996]\n",
            " [0.000]\n",
            " [0.989]\n",
            " [0.992]\n",
            " [0.832]\n",
            " [0.002]\n",
            " [1.000]\n",
            " [0.994]\n",
            " [0.955]\n",
            " [0.979]\n",
            " [0.960]\n",
            " [0.998]\n",
            " [0.014]\n",
            " [0.965]\n",
            " [0.978]\n",
            " [0.978]\n",
            " [0.991]\n",
            " [0.968]\n",
            " [0.000]\n",
            " [0.002]\n",
            " [0.995]\n",
            " [0.980]\n",
            " [0.001]\n",
            " [0.001]\n",
            " [0.003]\n",
            " [0.002]\n",
            " [0.950]\n",
            " [0.994]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.870]\n",
            " [0.934]\n",
            " [0.997]\n",
            " [0.103]\n",
            " [0.501]\n",
            " [0.970]\n",
            " [0.009]\n",
            " [0.000]\n",
            " [0.976]\n",
            " [0.000]\n",
            " [0.006]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.849]\n",
            " [0.001]\n",
            " [0.998]\n",
            " [0.091]\n",
            " [1.000]\n",
            " [0.021]\n",
            " [0.000]\n",
            " [0.991]\n",
            " [0.091]\n",
            " [0.968]\n",
            " [0.978]\n",
            " [0.991]\n",
            " [0.103]\n",
            " [0.000]\n",
            " [0.965]\n",
            " [0.992]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.973]\n",
            " [0.956]\n",
            " [0.995]\n",
            " [0.965]\n",
            " [0.007]\n",
            " [0.981]\n",
            " [0.091]\n",
            " [0.035]\n",
            " [0.091]\n",
            " [0.964]\n",
            " [0.992]\n",
            " [0.014]\n",
            " [0.705]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.990]\n",
            " [0.989]\n",
            " [0.991]\n",
            " [0.002]\n",
            " [0.103]\n",
            " [0.982]\n",
            " [0.001]\n",
            " [0.995]\n",
            " [0.999]\n",
            " [0.948]\n",
            " [0.006]\n",
            " [0.091]\n",
            " [0.983]\n",
            " [0.003]\n",
            " [0.091]\n",
            " [0.994]\n",
            " [0.984]\n",
            " [0.980]\n",
            " [0.004]\n",
            " [0.998]\n",
            " [0.004]\n",
            " [0.002]\n",
            " [0.996]\n",
            " [0.963]\n",
            " [0.006]\n",
            " [0.091]\n",
            " [0.993]\n",
            " [0.003]\n",
            " [0.099]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.000]\n",
            " [0.007]\n",
            " [0.978]\n",
            " [0.990]\n",
            " [0.091]\n",
            " [1.000]\n",
            " [0.992]\n",
            " [0.998]\n",
            " [0.965]\n",
            " [1.000]\n",
            " [0.016]\n",
            " [0.024]\n",
            " [0.996]\n",
            " [1.000]\n",
            " [0.998]\n",
            " [0.000]\n",
            " [0.993]\n",
            " [0.984]\n",
            " [0.964]\n",
            " [0.998]\n",
            " [0.980]\n",
            " [0.000]\n",
            " [0.993]\n",
            " [0.808]\n",
            " [0.000]\n",
            " [0.003]\n",
            " [0.091]\n",
            " [1.000]\n",
            " [0.834]\n",
            " [0.987]\n",
            " [0.832]\n",
            " [0.317]\n",
            " [0.000]\n",
            " [0.996]\n",
            " [0.001]\n",
            " [0.984]\n",
            " [0.103]\n",
            " [0.998]\n",
            " [0.000]\n",
            " [0.997]\n",
            " [0.001]\n",
            " [0.994]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.008]\n",
            " [0.993]\n",
            " [0.608]\n",
            " [0.989]\n",
            " [0.999]\n",
            " [0.003]\n",
            " [0.967]\n",
            " [0.962]\n",
            " [0.986]\n",
            " [0.998]\n",
            " [0.003]\n",
            " [0.001]\n",
            " [0.996]\n",
            " [0.967]\n",
            " [0.002]\n",
            " [0.994]\n",
            " [0.091]\n",
            " [0.068]\n",
            " [0.827]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.975]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.974]\n",
            " [0.940]\n",
            " [0.992]\n",
            " [0.000]\n",
            " [0.998]\n",
            " [0.985]\n",
            " [0.979]\n",
            " [0.983]\n",
            " [0.997]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.899]\n",
            " [0.135]\n",
            " [0.982]\n",
            " [0.001]\n",
            " [0.009]\n",
            " [0.980]\n",
            " [0.006]\n",
            " [0.001]\n",
            " [0.002]\n",
            " [0.229]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.996]\n",
            " [0.982]\n",
            " [0.001]\n",
            " [0.008]\n",
            " [0.001]\n",
            " [0.987]\n",
            " [0.000]\n",
            " [0.976]\n",
            " [0.001]\n",
            " [0.013]\n",
            " [0.833]\n",
            " [0.936]\n",
            " [0.990]\n",
            " [0.996]\n",
            " [0.839]\n",
            " [0.000]\n",
            " [0.991]\n",
            " [0.996]\n",
            " [0.091]\n",
            " [0.992]\n",
            " [0.991]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.924]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.987]\n",
            " [0.945]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.013]\n",
            " [0.997]\n",
            " [0.963]\n",
            " [0.962]\n",
            " [0.952]\n",
            " [0.904]\n",
            " [0.006]\n",
            " [0.091]\n",
            " [0.992]\n",
            " [0.999]\n",
            " [0.000]\n",
            " [0.002]\n",
            " [0.991]\n",
            " [0.998]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.979]\n",
            " [0.001]\n",
            " [0.988]\n",
            " [0.707]\n",
            " [0.004]\n",
            " [0.028]\n",
            " [0.904]\n",
            " [0.986]\n",
            " [0.990]\n",
            " [0.007]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.995]\n",
            " [0.001]\n",
            " [0.973]\n",
            " [0.964]\n",
            " [0.980]\n",
            " [0.091]\n",
            " [0.995]\n",
            " [0.978]\n",
            " [0.971]\n",
            " [0.988]\n",
            " [0.003]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.993]\n",
            " [0.988]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.002]\n",
            " [0.964]\n",
            " [0.001]\n",
            " [0.036]\n",
            " [0.999]\n",
            " [0.001]\n",
            " [0.998]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.021]\n",
            " [0.117]\n",
            " [0.003]\n",
            " [0.993]\n",
            " [0.246]\n",
            " [0.064]\n",
            " [0.990]\n",
            " [0.963]\n",
            " [0.765]\n",
            " [0.091]\n",
            " [0.014]\n",
            " [0.000]\n",
            " [0.986]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.001]\n",
            " [0.006]\n",
            " [0.979]\n",
            " [0.994]\n",
            " [0.984]\n",
            " [0.000]\n",
            " [0.994]\n",
            " [0.946]\n",
            " [0.995]\n",
            " [0.091]\n",
            " [0.979]\n",
            " [0.091]\n",
            " [0.989]\n",
            " [0.363]\n",
            " [0.975]\n",
            " [0.975]\n",
            " [0.103]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.965]\n",
            " [0.962]\n",
            " [0.103]\n",
            " [0.973]\n",
            " [0.982]\n",
            " [0.922]\n",
            " [0.988]\n",
            " [0.000]\n",
            " [0.013]\n",
            " [0.979]\n",
            " [0.003]\n",
            " [0.985]\n",
            " [0.997]\n",
            " [0.967]\n",
            " [0.020]\n",
            " [0.013]\n",
            " [0.964]\n",
            " [0.002]\n",
            " [0.044]\n",
            " [0.015]\n",
            " [0.001]\n",
            " [0.999]\n",
            " [0.091]\n",
            " [0.021]\n",
            " [0.983]\n",
            " [0.000]\n",
            " [0.578]\n",
            " [0.997]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.007]\n",
            " [0.996]\n",
            " [0.998]\n",
            " [0.002]\n",
            " [0.052]\n",
            " [0.986]\n",
            " [0.008]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.979]\n",
            " [0.990]\n",
            " [0.980]\n",
            " [0.001]\n",
            " [0.168]\n",
            " [0.868]\n",
            " [0.007]\n",
            " [0.995]\n",
            " [0.965]\n",
            " [0.991]\n",
            " [0.003]\n",
            " [0.934]\n",
            " [0.064]\n",
            " [0.001]\n",
            " [0.025]\n",
            " [0.958]\n",
            " [0.998]\n",
            " [0.944]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.999]\n",
            " [0.985]\n",
            " [0.000]\n",
            " [0.979]\n",
            " [0.005]\n",
            " [0.962]\n",
            " [0.006]\n",
            " [0.492]\n",
            " [0.091]\n",
            " [0.104]\n",
            " [0.000]\n",
            " [0.002]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.962]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.959]\n",
            " [0.985]\n",
            " [0.033]\n",
            " [0.971]\n",
            " [0.016]\n",
            " [0.103]\n",
            " [0.002]\n",
            " [0.896]\n",
            " [0.990]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.012]\n",
            " [0.991]\n",
            " [0.091]\n",
            " [0.002]\n",
            " [0.014]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.984]\n",
            " [0.999]\n",
            " [0.981]\n",
            " [0.037]\n",
            " [0.006]\n",
            " [0.944]\n",
            " [0.951]\n",
            " [0.003]\n",
            " [0.030]\n",
            " [0.083]\n",
            " [0.000]\n",
            " [0.103]\n",
            " [0.985]\n",
            " [0.957]\n",
            " [0.990]\n",
            " [0.954]\n",
            " [0.998]\n",
            " [0.007]\n",
            " [0.007]\n",
            " [0.885]\n",
            " [0.964]\n",
            " [0.135]\n",
            " [0.996]\n",
            " [0.960]\n",
            " [0.976]\n",
            " [0.081]\n",
            " [0.103]\n",
            " [0.007]\n",
            " [0.993]\n",
            " [0.001]\n",
            " [0.002]\n",
            " [0.304]\n",
            " [0.964]\n",
            " [0.000]\n",
            " [0.775]\n",
            " [0.997]\n",
            " [0.000]\n",
            " [0.032]\n",
            " [0.033]\n",
            " [0.810]\n",
            " [0.006]\n",
            " [0.000]\n",
            " [0.925]\n",
            " [0.010]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.997]\n",
            " [0.983]\n",
            " [0.002]\n",
            " [0.002]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.091]\n",
            " [0.998]\n",
            " [0.120]\n",
            " [0.014]\n",
            " [0.977]\n",
            " [0.987]\n",
            " [0.993]\n",
            " [0.999]\n",
            " [0.967]\n",
            " [0.994]\n",
            " [0.985]\n",
            " [0.992]\n",
            " [0.997]\n",
            " [0.995]\n",
            " [0.990]\n",
            " [0.995]\n",
            " [0.924]\n",
            " [0.000]\n",
            " [0.001]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.000]\n",
            " [0.990]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.995]\n",
            " [0.993]\n",
            " [0.995]\n",
            " [0.957]\n",
            " [0.103]\n",
            " [0.001]\n",
            " [0.971]\n",
            " [0.002]\n",
            " [0.103]\n",
            " [0.996]\n",
            " [0.957]\n",
            " [0.997]\n",
            " [0.922]\n",
            " [0.962]\n",
            " [0.000]\n",
            " [0.997]\n",
            " [0.890]\n",
            " [0.009]\n",
            " [0.091]\n",
            " [0.990]\n",
            " [0.007]\n",
            " [0.091]\n",
            " [0.000]\n",
            " [0.000]\n",
            " [0.890]\n",
            " [0.091]\n",
            " [0.994]\n",
            " [0.991]\n",
            " [0.998]\n",
            " [0.999]\n",
            " [0.124]\n",
            " [0.980]\n",
            " [0.015]\n",
            " [0.027]\n",
            " [0.996]\n",
            " [0.987]\n",
            " [0.949]\n",
            " [0.888]\n",
            " [0.957]\n",
            " [0.815]\n",
            " [0.092]\n",
            " [0.962]\n",
            " [0.000]\n",
            " [0.027]\n",
            " [0.010]\n",
            " [0.014]\n",
            " [0.013]\n",
            " [0.004]\n",
            " [0.998]\n",
            " [0.969]\n",
            " [0.012]\n",
            " [0.981]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [0.006]\n",
            " [0.989]\n",
            " [0.999]\n",
            " [0.051]\n",
            " [0.000]\n",
            " [0.091]\n",
            " [1.000]\n",
            " [0.000]\n",
            " [0.006]\n",
            " [0.025]\n",
            " [0.001]\n",
            " [0.003]\n",
            " [0.997]\n",
            " [0.979]\n",
            " [0.956]\n",
            " [0.977]\n",
            " [0.978]\n",
            " [0.091]\n",
            " [0.001]\n",
            " [0.997]\n",
            " [0.091]\n",
            " [0.980]\n",
            " [0.998]\n",
            " [0.979]\n",
            " [0.021]\n",
            " [0.091]\n",
            " [0.002]\n",
            " [0.024]\n",
            " [0.984]\n",
            " [0.000]\n",
            " [0.009]\n",
            " [0.067]\n",
            " [0.000]\n",
            " [0.945]\n",
            " [0.091]\n",
            " [0.976]\n",
            " [0.973]\n",
            " [0.013]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIUEXra2jyFD",
        "colab_type": "text"
      },
      "source": [
        "> ### Modele Evaluate\n",
        "\n",
        "* 가장 좋은 성능을 보인 모델을 사용하여 테스트 데이터 셋에 평가한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REAwtjEpca5P",
        "colab_type": "code",
        "outputId": "ae6d7baf-43ae-49b6-a994-b5ce6891fb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vgg_best_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "vgg_loss, vgg_acc = vgg_best_model.evaluate_generator(test_batches, steps = 50, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 6s 118ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBc0hntPg96H",
        "colab_type": "code",
        "outputId": "0f8de77d-c00d-40e5-ee6a-1610875cf663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(\"vgg_loss :\")\n",
        "print(vgg_loss)\n",
        "print()\n",
        "print(\"vgg_acc : \")\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vgg_loss :\n",
            "0.11006668876856565\n",
            "\n",
            "vgg_acc : \n",
            "0.9669999933242798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uewyE-aYqi2_",
        "colab_type": "text"
      },
      "source": [
        "> ### Build the network (Using resnet)\n",
        "* ResNet50을 사용하여 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joWwzqDeh3FV",
        "colab_type": "code",
        "outputId": "c992ab86-12f2-44e1-de65-eab125ad5ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6617
        }
      },
      "source": [
        "resnet = ResNet50(weights='imagenet',\n",
        "                  include_top=False,  \n",
        "                  input_shape=(64, 64, 3))\n",
        "resnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 16, 16, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 16, 16, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 16, 16, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 16, 16, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 512)    0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 4, 4, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 2, 2, 2048)   0           add_32[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6E7yr47sJI_",
        "colab_type": "code",
        "outputId": "623c203a-2eae-4b16-be40-424c1ddf5df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "resnet_model = models.Sequential()\n",
        "resnet_model.add(resnet)\n",
        "resnet_model.add(layers.Flatten())\n",
        "resnet_model.add(layers.Dense(256, activation='relu'))\n",
        "resnet_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "resnet.trainable = False\n",
        "resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2, 2, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 25,685,377\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bq-C5kbqmU3",
        "colab_type": "code",
        "outputId": "8e02783e-0bf3-40f3-b5b4-186982708200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "modelckpt = ModelCheckpoint(filepath=resnet_callbackpath)\n",
        "resnet_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = resnet_model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=367,\n",
        "                              epochs=10,\n",
        "                              validation_data=val_batches,\n",
        "                              validation_steps=50,\n",
        "                              callbacks=[modelckpt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "367/367 [==============================] - 1854s 5s/step - loss: 0.2427 - acc: 0.9248 - val_loss: 0.9758 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "367/367 [==============================] - 35s 94ms/step - loss: 0.1669 - acc: 0.9469 - val_loss: 0.8726 - val_acc: 0.5090\n",
            "Epoch 3/10\n",
            "367/367 [==============================] - 34s 93ms/step - loss: 0.1299 - acc: 0.9575 - val_loss: 0.8203 - val_acc: 0.4850\n",
            "Epoch 4/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.1229 - acc: 0.9590 - val_loss: 0.7820 - val_acc: 0.5210\n",
            "Epoch 5/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.1096 - acc: 0.9606 - val_loss: 0.7441 - val_acc: 0.4960\n",
            "Epoch 6/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.0968 - acc: 0.9654 - val_loss: 0.7709 - val_acc: 0.4910\n",
            "Epoch 7/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.0946 - acc: 0.9681 - val_loss: 0.8458 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.0902 - acc: 0.9703 - val_loss: 0.9194 - val_acc: 0.5090\n",
            "Epoch 9/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.0778 - acc: 0.9733 - val_loss: 1.2453 - val_acc: 0.4820\n",
            "Epoch 10/10\n",
            "367/367 [==============================] - 34s 92ms/step - loss: 0.0766 - acc: 0.9738 - val_loss: 1.0045 - val_acc: 0.5050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxwEmI_mDB71",
        "colab_type": "text"
      },
      "source": [
        "> ### resnet add Dropout\n",
        "* 드롭아웃을 추가\n",
        "* Dense 레이어 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEG4EYgbsaKW",
        "colab_type": "code",
        "outputId": "8265f1d5-71d7-4434-a257-c862d73e3e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "resnet2_model = models.Sequential()\n",
        "resnet2_model.add(resnet)\n",
        "resnet2_model.add(layers.Flatten())\n",
        "resnet2_model.add(layers.Dropout(0.5))\n",
        "resnet2_model.add(layers.Dense(1024, activation='relu'))\n",
        "resnet2_model.add(layers.Dense(512, activation='relu'))\n",
        "resnet2_model.add(layers.Dense(256, activation='relu'))\n",
        "resnet2_model.add(layers.Dense(1, activation='sigmoid'))\n",
        "resnet.trainable = False\n",
        "resnet2_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2, 2, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              8389632   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 32,633,729\n",
            "Trainable params: 9,046,017\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNZIDzV6DT_5",
        "colab_type": "code",
        "outputId": "9b484e64-4e7f-4ba5-e2bb-c21ae31a0db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "modelckpt = ModelCheckpoint(filepath=resnet_callbackpath2)\n",
        "resnet2_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = resnet2_model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=367,\n",
        "                              epochs=10,\n",
        "                              validation_data=val_batches,\n",
        "                              validation_steps=50,\n",
        "                              callbacks=[modelckpt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "367/367 [==============================] - 55s 149ms/step - loss: 0.3197 - acc: 0.8888 - val_loss: 0.7194 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "367/367 [==============================] - 47s 129ms/step - loss: 0.2334 - acc: 0.9253 - val_loss: 0.7129 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "367/367 [==============================] - 48s 131ms/step - loss: 0.2073 - acc: 0.9339 - val_loss: 0.7319 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "367/367 [==============================] - 47s 128ms/step - loss: 0.1908 - acc: 0.9379 - val_loss: 0.7368 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "367/367 [==============================] - 45s 121ms/step - loss: 0.1852 - acc: 0.9413 - val_loss: 0.8121 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "367/367 [==============================] - 43s 117ms/step - loss: 0.1821 - acc: 0.9437 - val_loss: 0.7573 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "367/367 [==============================] - 44s 119ms/step - loss: 0.1920 - acc: 0.9477 - val_loss: 0.7714 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "367/367 [==============================] - 45s 122ms/step - loss: 0.1690 - acc: 0.9497 - val_loss: 0.7991 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "367/367 [==============================] - 44s 120ms/step - loss: 0.1696 - acc: 0.9512 - val_loss: 0.8005 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "367/367 [==============================] - 45s 123ms/step - loss: 0.1800 - acc: 0.9488 - val_loss: 0.9357 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXuw4yiWEKsF",
        "colab_type": "code",
        "outputId": "03c6e2de-67b4-4169-94bb-b02f7c8e7e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resnet_loss, resnet_acc = resnet2_model.evaluate_generator(test_batches, steps = 50, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 5s 108ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRdeZErJhiFE",
        "colab_type": "code",
        "outputId": "5f721d0a-4271-406a-b62b-ea664e525c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(\"resnet_loss :\")\n",
        "print(resnet_loss)\n",
        "print()\n",
        "print(\"resnet_acc : \")\n",
        "print(resnet_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet_loss :\n",
            "0.7104809832572937\n",
            "\n",
            "resnet_acc : \n",
            "0.4990000030398369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Altyo3R2y0Lo",
        "colab_type": "text"
      },
      "source": [
        "#클래스 활성화의 히트맵 시각화하기 (Grad-CAM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jDrzqe9yt4K",
        "colab_type": "code",
        "outputId": "9e202c0b-7f97-4373-cec5-6686a397a53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "model = conv_base\n",
        "\n",
        "img_path = '/content/gdrive/My Drive/DeepLearning_Project/2/malware_image_dataset/test/worm/worm (100).png'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(256,256))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "x = np.expand_dims(x,axis=0)\n",
        "\n",
        "x = preprocess_input(x)\n",
        "\n",
        "african_elephant_output = model.output[:,0]\n",
        "\n",
        "last_conv_layer = model.get_layer('block5_conv3')\n",
        "\n",
        "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
        "\n",
        "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
        "\n",
        "iterate = K.function([model.input],[pooled_grads,last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "for i in range(512):\n",
        "  conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
        "  \n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.matshow(heatmap)\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap = np.uint8(255*heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = heatmap * 0.4 + img\n",
        "cv2.imwrite('/content/gdrive/My Drive/DeepLearning_Project/2/CAM.jpg', superimposed_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBADF/wGoVECIkM89ggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKHwWi093U2Q",
        "colab_type": "text"
      },
      "source": [
       
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug5eGRaq1luV",
        "colab_type": "text"
      },
      "source": [
        "> ### Trouble Shooting\n",
        "* 데이터셋은 grayscale 이미지 인데, vgg16 모델은 3차원 rgb 모델을 입력으로 받는다.\n",
        "    * ImageDataGenerator에서 color_mode='grayscale' 이렇게 불러왔었는데, 그냥 디폴트로 하게 되면 grayscale을 rgb로 convert해서 불러온다\n",
        "* load_model에서 /usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. warnings.warn('Error in loading the saved optimizer  발생\n",
        "  * load_model할때 인자로 compile=False 추가\n",
        "* resnet모델 정확도가 너무 낮음.\n",
        "  * Dropout 적용, 위에 층 추가 등 다양한 방법을 시도해 보았지만 해결하지 못하였음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Npig_5Z33GX",
        "colab_type": "text"
      },
      "source": [
        "> ### Reference\n",
        "* ppt 맨 뒷장에 표시"
      ]
    }
  ]
}
